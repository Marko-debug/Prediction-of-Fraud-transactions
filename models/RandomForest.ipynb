{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def PCA_change(df, cols, n_components, prefix='PCA_', rand_seed=4):\n",
    "    pca = PCA(n_components=n_components, random_state=rand_seed)\n",
    "    principalComponents = pca.fit_transform(df[cols])\n",
    "    principalDf = pd.DataFrame(principalComponents)\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "    principalDf.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n",
    "    df = pd.concat([df, principalDf], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 434)\n",
      "(506691, 433)\n"
     ]
    }
   ],
   "source": [
    "df_trans = pd.read_csv('../input/train_transaction.csv')\n",
    "df_test_trans = pd.read_csv('../input/test_transaction.csv')\n",
    "\n",
    "df_id = pd.read_csv('../input/train_identity.csv')\n",
    "df_test_id = pd.read_csv('../input/test_identity.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "df_train = df_trans.merge(df_id, how='left', on='TransactionID')\n",
    "df_test = df_test_trans.merge(df_test_id, how='left', on='TransactionID')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "# Standardizing column names\n",
    "df_train.columns = df_train.columns.str.replace('-', '_')\n",
    "df_test.columns = df_test.columns.str.replace('-', '_')\n",
    "\n",
    "# y_train = df_train['isFraud'].copy()\n",
    "del df_trans, df_id, df_test_trans, df_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Label Encoding\n",
    "for f in df_train.drop('isFraud', axis=1).columns:\n",
    "    if df_train[f].dtype=='object' or df_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(df_train[f].values) + list(df_test[f].values))\n",
    "        df_train[f] = lbl.transform(list(df_train[f].values))\n",
    "        df_test[f] = lbl.transform(list(df_test[f].values))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 525.45 Mb (72.1% reduction)\n",
      "Mem. usage decreased to 458.09 Mb (71.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marek\\AppData\\Local\\Temp\\ipykernel_26316\\3305452335.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test['isFraud'] = 'test'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(590540, 125)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['isFraud'] = 'test'\n",
    "df = pd.concat([df_train, df_test], axis=0, sort=False )\n",
    "df = df.reset_index()\n",
    "df = df.drop('index', axis=1)\n",
    "\n",
    "mas_v = df_train.columns[55:394]\n",
    "\n",
    "for col in mas_v:\n",
    "    df[col] = df[col].fillna((df[col].min() - 2))\n",
    "    df[col] = (minmax_scale(df[col], feature_range=(0,1)))\n",
    "\n",
    "    \n",
    "df = PCA_change(df, mas_v, prefix='PCA_V_', n_components=30)\n",
    "\n",
    "df_train, df_test = df[df['isFraud'] != 'test'], df[df['isFraud'] == 'test'].drop('isFraud', axis=1)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.sort_values('TransactionDT').drop(['isFraud', \n",
    "                                                      'TransactionDT', \n",
    "                                                      #'Card_ID'\n",
    "                                                     ],\n",
    "                                                     axis=1)\n",
    "y_train = df_train.sort_values('TransactionDT')['isFraud'].astype(bool)\n",
    "\n",
    "X_test = df_test.sort_values('TransactionDT').drop(['TransactionDT',\n",
    "                                                    #'Card_ID'\n",
    "                                                   ], \n",
    "                                                   axis=1)\n",
    "del df_train\n",
    "test = df_test[[\"TransactionDT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TransactionID', 'TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'PCA_V_0', 'PCA_V_1', 'PCA_V_2', 'PCA_V_3', 'PCA_V_4', 'PCA_V_5', 'PCA_V_6', 'PCA_V_7', 'PCA_V_8', 'PCA_V_9', 'PCA_V_10', 'PCA_V_11', 'PCA_V_12', 'PCA_V_13', 'PCA_V_14', 'PCA_V_15', 'PCA_V_16', 'PCA_V_17', 'PCA_V_18', 'PCA_V_19', 'PCA_V_20', 'PCA_V_21', 'PCA_V_22', 'PCA_V_23', 'PCA_V_24', 'PCA_V_25', 'PCA_V_26', 'PCA_V_27', 'PCA_V_28', 'PCA_V_29']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [4:01:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit on training data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_combinations) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(total_combinations)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m   1021\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    967\u001b[0m         clone(base_estimator),\n\u001b[0;32m    968\u001b[0m         X,\n\u001b[0;32m    969\u001b[0m         y,\n\u001b[0;32m    970\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    971\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    972\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    973\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    974\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    975\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    976\u001b[0m     )\n\u001b[0;32m    977\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    978\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params),\n\u001b[0;32m    979\u001b[0m         \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrouted_params\u001b[39m.\u001b[39;49msplitter\u001b[39m.\u001b[39;49msplit)),\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    981\u001b[0m )\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[39m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1763\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],  # Number of trees\n",
    "    'max_depth': [10, 20, 30],        # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples needed to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum samples per leaf node\n",
    "    'max_features': ['sqrt', 'log2']  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Use GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf, param_grid=param_grid, \n",
    "    scoring='roc_auc', cv=2, verbose=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "\n",
    "# Fit on training data\n",
    "with tqdm(total=total_combinations) as pbar:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    pbar.update(total_combinations)\n",
    "\n",
    "# Get the best parameters\n",
    "best_rf_params = grid_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_rf_params)\n",
    "\n",
    "# Train the optimized Random Forest model\n",
    "final_rf = RandomForestClassifier(**best_rf_params, random_state=42, n_jobs=-1)\n",
    "final_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training data\n",
    "y_pred = final_rf.predict(X_train)\n",
    "y_pred_proba = final_rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "roc_auc = roc_auc_score(y_train, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# Print Metrics\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toto spodne je zatial pokusne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import time\n",
    "def objective(params):\n",
    "    time1 = time.time()\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
    "        'subsample': \"{:.2f}\".format(params['subsample']),\n",
    "        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n",
    "        'reg_lambda': \"{:.3f}\".format(params['reg_lambda']),\n",
    "        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree'])\n",
    "    }\n",
    "\n",
    "    print(\"\\n############## New Run ################\")\n",
    "    print(f\"params = {params}\")\n",
    "    FOLDS = 7\n",
    "    count=1\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    tss = TimeSeriesSplit(n_splits=FOLDS)\n",
    "    y_preds = np.zeros(sample_submission.shape[0])\n",
    "    y_oof = np.zeros(X_train.shape[0])\n",
    "    score_mean = 0\n",
    "    for tr_idx, val_idx in tss.split(X_train, y_train):\n",
    "        clf = xgb.XGBClassifier(\n",
    "            n_estimators=600, random_state=4, \n",
    "            **params\n",
    "        )\n",
    "\n",
    "        X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        clf.fit(X_tr, y_tr)\n",
    "        #y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "        #print(y_pred_train)\n",
    "        score = make_scorer(roc_auc_score)(clf, X_vl, y_vl)\n",
    "        # plt.show()\n",
    "        score_mean += score\n",
    "        print(f'{count} CV - score: {round(score, 4)}')\n",
    "        count += 1\n",
    "    time2 = time.time() - time1\n",
    "    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n",
    "    gc.collect()\n",
    "    print(f'Mean ROC_AUC: {score_mean / FOLDS}')\n",
    "    del X_tr, X_vl, y_tr, y_vl, clf, score\n",
    "    return -(score_mean / FOLDS)\n",
    "\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 7, 23, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "############## New Run ################\n",
      "params = {'max_depth': 7, 'gamma': '0.688', 'subsample': '0.40', 'reg_alpha': '0.388', 'reg_lambda': '0.020', 'learning_rate': '0.031', 'colsample_bytree': '0.320'}\n",
      "1 CV - score: 0.6726                                  \n",
      "2 CV - score: 0.6652                                  \n",
      "3 CV - score: 0.7154                                  \n",
      "4 CV - score: 0.6563                                  \n",
      "5 CV - score: 0.7128                                  \n",
      "6 CV - score: 0.6598                                  \n",
      "7 CV - score: 0.6588                                  \n",
      "Total Time Run: 4.8                                   \n",
      "Mean ROC_AUC: 0.677278002328681                       \n",
      "                                                                                   \n",
      "############## New Run ################\n",
      "params = {'max_depth': 16, 'gamma': '0.355', 'subsample': '0.90', 'reg_alpha': '0.064', 'reg_lambda': '0.014', 'learning_rate': '0.079', 'colsample_bytree': '0.466'}\n",
      "1 CV - score: 0.6466                                                               \n",
      "2 CV - score: 0.6423                                                               \n",
      "3 CV - score: 0.714                                                                \n",
      "4 CV - score: 0.6455                                                               \n",
      "5 CV - score: 0.7141                                                               \n",
      "6 CV - score: 0.6584                                                               \n",
      "7 CV - score: 0.6518                                                               \n",
      "Total Time Run: 5.88                                                               \n",
      "Mean ROC_AUC: 0.6675144951012971                                                   \n",
      "                                                                                   \n",
      "############## New Run ################\n",
      "params = {'max_depth': 12, 'gamma': '0.196', 'subsample': '0.70', 'reg_alpha': '0.365', 'reg_lambda': '0.103', 'learning_rate': '0.138', 'colsample_bytree': '0.692'}\n",
      "1 CV - score: 0.6623                                                               \n",
      "2 CV - score: 0.6564                                                               \n",
      "3 CV - score: 0.7235                                                               \n",
      "4 CV - score: 0.656                                                                \n",
      "5 CV - score: 0.7234                                                               \n",
      "6 CV - score: 0.6761                                                               \n",
      "7 CV - score: 0.6648                                                               \n",
      "Total Time Run: 5.66                                                               \n",
      "Mean ROC_AUC: 0.6803462432013865                                                   \n",
      "                                                                                    \n",
      "############## New Run ################\n",
      "params = {'max_depth': 22, 'gamma': '0.396', 'subsample': '0.90', 'reg_alpha': '0.391', 'reg_lambda': '0.396', 'learning_rate': '0.150', 'colsample_bytree': '0.504'}\n",
      "1 CV - score: 0.6586                                                                \n",
      "2 CV - score: 0.648                                                                 \n",
      "3 CV - score: 0.709                                                                 \n",
      "4 CV - score: 0.641                                                                 \n",
      "5 CV - score: 0.7074                                                                \n",
      "6 CV - score: 0.6568                                                                \n",
      "7 CV - score: 0.6493                                                                \n",
      "Total Time Run: 4.23                                                                \n",
      "Mean ROC_AUC: 0.6671663808067161                                                    \n",
      "                                                                                    \n",
      "############## New Run ################\n",
      "params = {'max_depth': 19, 'gamma': '0.146', 'subsample': '0.90', 'reg_alpha': '0.303', 'reg_lambda': '0.089', 'learning_rate': '0.028', 'colsample_bytree': '0.745'}\n",
      "1 CV - score: 0.6614                                                                \n",
      "2 CV - score: 0.65                                                                  \n",
      "3 CV - score: 0.7211                                                                \n",
      "4 CV - score: 0.6536                                                                \n",
      " 16%|█▌        | 4/25 [25:51<2:15:44, 387.83s/trial, best loss: -0.6803462432013865]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set algoritm parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Run Hyperopt tuning\u001b[39;00m\n\u001b[0;32m      3\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m----> 4\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print best parameters\u001b[39;00m\n\u001b[0;32m      7\u001b[0m best_params \u001b[38;5;241m=\u001b[39m space_eval(space, best)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[27], line 38\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     35\u001b[0m X_tr, X_vl \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[tr_idx, :], X_train\u001b[38;5;241m.\u001b[39miloc[val_idx, :]\n\u001b[0;32m     36\u001b[0m y_tr, y_vl \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[tr_idx], y_train\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[1;32m---> 38\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#y_pred_train = clf.predict_proba(X_vl)[:,1]\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#print(y_pred_train)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m score \u001b[38;5;241m=\u001b[39m make_scorer(roc_auc_score)(clf, X_vl, y_vl)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1579\u001b[0m model, metric, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1580\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1581\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1582\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1597\u001b[0m )\n\u001b[1;32m-> 1599\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1600\u001b[0m     params,\n\u001b[0;32m   1601\u001b[0m     train_dmatrix,\n\u001b[0;32m   1602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1603\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1604\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1605\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1606\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1607\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1608\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1609\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1610\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[0;32m   1611\u001b[0m )\n\u001b[0;32m   1613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1614\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, iteration\u001b[39m=\u001b[39;49mi, fobj\u001b[39m=\u001b[39;49mobj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set algoritm parameters\n",
    "# Run Hyperopt tuning\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=25, trials=trials)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = space_eval(space, best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af8d963e8c18f23cec2bad6a5d6829aca318c1abb40ceb23a7acab4dc52a4f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
